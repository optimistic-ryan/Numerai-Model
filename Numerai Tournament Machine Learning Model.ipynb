{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEbD_WTWQi91"
      },
      "outputs": [],
      "source": [
        "  # installing required libraries\n",
        "  # numerapi, for facilitating data download and predictions uploading\n",
        "  # catboost, for modeling and making predictions\n",
        "  !pip install numerapi\n",
        "  !pip install catboost\n",
        "  import os\n",
        "  import gc\n",
        "  import csv\n",
        "  import glob\n",
        "  import time\n",
        "  from pathlib import Path\n",
        "\n",
        "  import numerapi\n",
        "\n",
        "  import scipy\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  from catboost import CatBoostRegressor\n",
        "  from sklearn.decomposition import PCA\n",
        "  from sklearn.impute import SimpleImputer\n",
        "  from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "  from sklearn.linear_model import Lasso"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  napi = numerapi.NumerAPI(verbosity=\"info\")\n",
        "  # download current dataset\n",
        "  napi.download_current_dataset(unzip=True)\n",
        "\n",
        "  current_ds = napi.get_current_round()\n",
        "  latest_round = os.path.join('numerai_dataset_'+str(current_ds))\n",
        "  TOURNAMENT_NAME = \"nomi\"\n",
        "  TARGET_NAME = f\"target\"\n",
        "  PREDICTION_NAME = f\"prediction\"\n",
        "\n",
        "  BENCHMARK = 0\n",
        "  BAND = 0.2"
      ],
      "metadata": {
        "id": "ddDg7pfZQpw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Submissions are scored by spearman correlation\n",
        "  def score(df):\n",
        "      # method=\"first\" breaks ties based on order in array\n",
        "      return np.corrcoef(\n",
        "          df[TARGET_NAME],\n",
        "          df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n",
        "      )[0, 1]\n",
        "\n",
        "  def correlation(predictions, targets):\n",
        "      ranked_preds = predictions.rank(pct=True, method=\"first\")\n",
        "      return np.corrcoef(ranked_preds, targets)[0, 1]\n",
        "\n",
        "  # The payout function\n",
        "  def payout(scores):\n",
        "      return ((scores - BENCHMARK) / BAND).clip(lower=-1, upper=1)\n",
        "\n",
        "\n",
        "  # Read the csv file into a pandas Dataframe\n",
        "  def read_csv(file_path):\n",
        "      with open(file_path, 'r') as f:\n",
        "          column_names = next(csv.reader(f))\n",
        "          dtypes = {x: np.float16 for x in column_names if\n",
        "                    x.startswith(('feature', 'target'))}\n",
        "      return pd.read_csv(file_path, dtype=dtypes)"
      ],
      "metadata": {
        "id": "y18OpTHqQsSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  print(\"# Loading data...\")\n",
        "  # The training data is used to train your model how to predict the targets.\n",
        "  training_data = read_csv(os.path.join(latest_round, \"numerai_training_data.csv\")).set_index(\"id\")\n",
        "  # The tournament data is the data that Numerai uses to evaluate your model.\n",
        "  tournament_data = read_csv(os.path.join(latest_round, \"numerai_tournament_data.csv\")).set_index(\"id\")\n",
        "\n",
        "  example_preds = read_csv(os.path.join(latest_round, \"example_predictions.csv\"))\n",
        "\n",
        "  validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "  feature_names = [f for f in training_data.columns if f.startswith(\"feature\")]\n",
        "  print(f\"Loaded {len(feature_names)} features\")\n",
        "\n",
        "  cols = feature_names+[TARGET_NAME]"
      ],
      "metadata": {
        "id": "35QZHT8jQ0Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Feature engineering\n",
        "  # Let's add some interaction features and some polynomial features\n",
        "  def engineer_features(df):\n",
        "      # Create interaction features\n",
        "      interaction_cols = [('feature_1', 'feature_2'), ('feature_1', 'feature_3'), ('feature_2', 'feature_3')]\n",
        "      for col1, col2 in interaction_cols:\n",
        "          if col1 in df.columns and col2 in df.columns:\n",
        "              df[col1] = pd.to_numeric(df[col1], errors='coerce')\n",
        "              df[col2] = pd.to_numeric(df[col2], errors='coerce')\n",
        "              df[f'{col1}_{col2}'] = df[col1] * df[col2]\n",
        "      \n",
        "      # Create polynomial features\n",
        "      poly_cols = ['feature_1', 'feature_2', 'feature_3']\n",
        "      for col in poly_cols:\n",
        "          if col in df.columns:\n",
        "              df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "              df[f'{col}^2'] = df[col] ** 2\n",
        "              df[f'{col}^3'] = df[col] ** 3\n",
        "          \n",
        "      # Impute missing values\n",
        "      imputer = SimpleImputer(strategy='mean')\n",
        "      df[feature_names] = imputer.fit_transform(df[feature_names])\n",
        "      \n",
        "      return df"
      ],
      "metadata": {
        "id": "rXr7RszrQ3J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  training_data = engineer_features(training_data)\n",
        "  validation_data = engineer_features(validation_data)\n",
        "  tournament_data = engineer_features(tournament_data)\n",
        "\n",
        "  # Hyperparameter tuning\n",
        "  # Let's tune the learning rate and max_depth hyperparameters using GridSearchCV\n",
        "  params = {\n",
        "      'task_type': 'GPU'\n",
        "  }\n",
        "\n",
        "  estimator = CatBoostRegressor(**params)\n",
        "\n",
        "  grid = {\n",
        "      'learning_rate': [0.1, 0.01, 0.001],\n",
        "      'max_depth': [3, 5, 7]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(estimator, grid, cv=3, n_jobs=-1, verbose=3)\n",
        "  grid_search.fit(training_data[feature_names].astype(np.float32), training_data[TARGET_NAME].astype(np.float32))\n",
        "\n",
        "  best_params = grid_search.best_params_\n",
        "\n",
        "  print(f\"Best hyperparameters: {best_params}\")"
      ],
      "metadata": {
        "id": "PsiuRUbGRCR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Ensembling\n",
        "  # Let's train 5 CatBoost models with different random seeds and combine their predictions\n",
        "  n_models = 5\n",
        "  models = []\n",
        "  for i in range(n_models):\n",
        "      model = CatBoostRegressor(**params, **best_params, random_seed=i)\n",
        "      model.fit(training_data[feature_names].astype(np.float32), training_data[TARGET_NAME].astype(np.float32))\n",
        "      models.append(model)\n",
        "\n",
        "  def ensemble_predict(models, X):\n",
        "      return np.mean([model.predict(X) for model in models], axis=0)\n",
        "\n",
        "  training_data[PREDICTION_NAME] = ensemble_predict(models, training_data[feature_names].astype(np.float32))\n",
        "  tournament_data[PREDICTION_NAME] = ensemble_predict(models, tournament_data[feature_names].astype(np.float32))"
      ],
      "metadata": {
        "id": "-rITcQvHRQyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Regularization\n",
        "  # Let's add L1 regularization to the models\n",
        "  reg_params = {'alpha': 0.01}\n",
        "\n",
        "  for model in models:\n",
        "      model.add_regularizer(Lasso(**reg_params))"
      ],
      "metadata": {
        "id": "EBQdGQhlRTG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Validation strategy\n",
        "  # Let's use 5-fold cross-validation to evaluate model performance\n",
        "  scores = cross_val_score(estimator, training_data[feature_names].astype(np.float32), training_data[TARGET_NAME].astype(np.float32), cv=5, scoring=score)\n",
        "\n",
        "  print(f\"On training the correlation has mean {scores.mean()} and std {scores.std()}\")\n",
        "  print(f\"On training the average per-era payout is {payout(scores).mean()}\")"
      ],
      "metadata": {
        "id": "pjp8ltGrRWsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Handling missing values\n",
        "  # Let's impute missing values using the mean value of each feature\n",
        "  imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "  training_data[feature_names] = imputer.fit_transform(training_data[feature_names])\n",
        "  validation_data[feature_names] = imputer.transform(validation_data[feature_names])\n",
        "  tournament_data[feature_names] = imputer.transform(tournament_data[feature_names])"
      ],
      "metadata": {
        "id": "5iOTVmC6RY9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Dimensionality reduction\n",
        "  # Let's use PCA to reduce the number of features to 100\n",
        "  pca = PCA(n_components=100)\n",
        "\n",
        "  training_data[feature_names] = pca.fit_transform(training_data[feature_names])\n",
        "  validation_data[feature_names] = pca.transform(validation_data[feature_names])\n",
        "  tournament_data[feature_names] = pca.transform(tournament_data[feature_names])"
      ],
      "metadata": {
        "id": "wfJnHuL0RbJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Model selection\n",
        "  # Let's try a LightGBM model and compare its performance to the CatBoost models\n",
        "  from lightgbm import LGBMRegressor\n",
        "\n",
        "  lgbm_params = {\n",
        "      'objective': 'regression',\n",
        "      'boosting_type': 'gbdt',\n",
        "      'learning_rate': 0.1,\n",
        "      'max_depth': 7,\n",
        "      'n_estimators': 1000,\n",
        "      'subsample': 0.8,\n",
        "      'colsample_bytree': 0.8,\n",
        "      'reg_alpha': 0.01,\n",
        "      'reg_lambda': 0.01,\n",
        "      'random_state': 42\n",
        "  }\n",
        "\n",
        "  lgbm = LGBMRegressor(**lgbm_params)\n",
        "  lgbm.fit(training_data[feature_names], training_data[TARGET_NAME])\n",
        "  training_data['lgbm_prediction'] = lgbm.predict(training_data[feature_names])\n",
        "  tournament_data['lgbm_prediction'] = lgbm.predict(tournament_data[feature_names])\n",
        "\n",
        "  lgbm_scores = cross_val_score(lgbm, training_data[feature_names], training_data[TARGET_NAME], cv=5, scoring=score)\n",
        "  print(f\"On training the correlation has mean {lgbm_scores.mean()} and std {lgbm_scores.std()}\")\n",
        "  print(f\"On training the average per-era payout is {payout(lgbm_scores).mean()}\")"
      ],
      "metadata": {
        "id": "8L5R_ctMRdF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Final predictions\n",
        "  # Let's combine the predictions from the CatBoost models and the LightGBM model\n",
        "  tournament_data[PREDICTION_NAME] = (tournament_data[PREDICTION_NAME] + tournament_data['lgbm_prediction']) / 2\n",
        "  tournament_data[PREDICTION_NAME].to_csv(f\"{TOURNAMENT_NAME}_{current_ds}_submission.csv\")"
      ],
      "metadata": {
        "id": "EeTbXSrlRhsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  tournament_data[PREDICTION_NAME]=example_preds['prediction'].values\n",
        "\n",
        "  # Check the per-era correlations on the validation set (out of sample)\n",
        "  validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
        "  validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
        "  print(f\"On validation the correlation has mean {validation_correlations.mean()} and \"\n",
        "          f\"std {validation_correlations.std()}\")\n",
        "  print(f\"On validation the average per-era payout is {payout(validation_correlations).mean()}\")"
      ],
      "metadata": {
        "id": "ePA2gFzLRmea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}